/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2023-10-31 20:21:40.168369: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2023-10-31 20:21:40.168429: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2023-10-31 20:21:40.168463: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-10-31 20:21:41.289217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
prepare tokenizer
Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:01<00:00, 895kB/s]
Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 7.26MB/s]
Downloading (…)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 2.79MB/s]
Downloading (…)okenizer_config.json: 100% 824/824 [00:00<00:00, 5.24MB/s]
Using DreamBooth method.
prepare images.
found directory /content/drive/MyDrive/AI_PICS/training/elisabeth_borne_512px/100_elisabeth_borne_512px contains 61 image files
No caption file found for 61 images. Training will continue without captions for these images. If class token exists, it will be used. / 61枚の画像にキャプションファイルが見つかりませんでした。これらの画像についてはキャプションなしで学習を続行します。class tokenが存在する場合はそれを使います。
/content/drive/MyDrive/AI_PICS/training/elisabeth_borne_512px/100_elisabeth_borne_512px/000543771_896x598_c.jpg
/content/drive/MyDrive/AI_PICS/training/elisabeth_borne_512px/100_elisabeth_borne_512px/000_32D37CP-e1656149834438.jpg
/content/drive/MyDrive/AI_PICS/training/elisabeth_borne_512px/100_elisabeth_borne_512px/000_33DV897.jpg
/content/drive/MyDrive/AI_PICS/training/elisabeth_borne_512px/100_elisabeth_borne_512px/000_33YY96N.jpg
/content/drive/MyDrive/AI_PICS/training/elisabeth_borne_512px/100_elisabeth_borne_512px/001348762_896x598_c.jpg
/content/drive/MyDrive/AI_PICS/training/elisabeth_borne_512px/100_elisabeth_borne_512px/090662720142-web-tete.jpg... and 56 more
6100 train images with repeating.
0 reg images.
no regularization images / 正則化画像が見つかりませんでした
[Dataset 0]
  batch_size: 1
  resolution: (512, 512)
  enable_bucket: True
  min_bucket_reso: 256
  max_bucket_reso: 2048
  bucket_reso_steps: 64
  bucket_no_upscale: True

  [Subset 0 of Dataset 0]
    image_dir: "/content/drive/MyDrive/AI_PICS/training/elisabeth_borne_512px/100_elisabeth_borne_512px"
    image_count: 61
    num_repeats: 100
    shuffle_caption: False
    keep_tokens: 0
    caption_dropout_rate: 0.0
    caption_dropout_every_n_epoches: 0
    caption_tag_dropout_rate: 0.0
    caption_prefix: None
    caption_suffix: None
    color_aug: False
    flip_aug: False
    face_crop_aug_range: None
    random_crop: False
    token_warmup_min: 1,
    token_warmup_step: 0,
    is_reg: False
    class_tokens: elisabeth_borne_512px
    caption_extension: .caption


[Dataset 0]
loading image sizes.
100% 61/61 [00:03<00:00, 19.65it/s]
make buckets
min_bucket_reso and max_bucket_reso are ignored if bucket_no_upscale is set, because bucket reso is defined by image size automatically / bucket_no_upscaleが指定された場合は、bucketの解像度は画像サイズから自動計算されるため、min_bucket_resoとmax_bucket_resoは無視されます
number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）
bucket 0: resolution (512, 512), count: 6100
mean ar error (without repeats): 0.0
preparing accelerator
loading model for process 0/1
load Diffusers pretrained models: stabilityai/stable-diffusion-2-1
Downloading (…)ain/model_index.json: 100% 537/537 [00:00<00:00, 2.85MB/s]
Fetching 9 files:   0% 0/9 [00:00<?, ?it/s]
Downloading (…)_encoder/config.json: 100% 633/633 [00:00<00:00, 3.31MB/s]

Downloading (…)cheduler_config.json: 100% 345/345 [00:00<00:00, 1.48MB/s]

Downloading (…)ch_model.safetensors:   0% 0.00/3.46G [00:00<?, ?B/s]

Downloading (…)ch_model.safetensors:   0% 0.00/335M [00:00<?, ?B/s]
Downloading (…)ch_model.safetensors:   1% 41.9M/3.46G [00:00<00:08, 384MB/s]

Downloading (…)ch_model.safetensors:   6% 21.0M/335M [00:00<00:02, 153MB/s]
Downloading (…)ch_model.safetensors:   3% 94.4M/3.46G [00:00<00:07, 454MB/s]

Downloading (…)ch_model.safetensors:  22% 73.4M/335M [00:00<00:00, 328MB/s]
Downloading (…)ch_model.safetensors:   4% 147M/3.46G [00:00<00:07, 473MB/s] 

Downloading (…)ch_model.safetensors:  38% 126M/335M [00:00<00:00, 400MB/s] 
Downloading (…)ch_model.safetensors:   6% 199M/3.46G [00:00<00:06, 485MB/s]

Downloading (…)ch_model.safetensors:  53% 178M/335M [00:00<00:00, 439MB/s]
Downloading (…)ch_model.safetensors:   7% 252M/3.46G [00:00<00:06, 476MB/s]

Downloading (…)ch_model.safetensors:  69% 231M/335M [00:00<00:00, 450MB/s]


Downloading model.safetensors:   0% 0.00/1.36G [00:00<?, ?B/s]
Downloading (…)ch_model.safetensors:   9% 304M/3.46G [00:00<00:06, 483MB/s]

Downloading (…)ch_model.safetensors:  85% 283M/335M [00:00<00:00, 463MB/s]


Downloading model.safetensors:   2% 21.0M/1.36G [00:00<00:09, 146MB/s]
Downloading (…)ch_model.safetensors:  10% 357M/3.46G [00:00<00:06, 448MB/s]

Downloading (…)ch_model.safetensors: 100% 335M/335M [00:00<00:00, 409MB/s]



Downloading model.safetensors:   4% 52.4M/1.36G [00:00<00:05, 226MB/s]
Downloading (…)ch_model.safetensors:  12% 409M/3.46G [00:00<00:06, 449MB/s]

Downloading (…)rocessor_config.json: 100% 342/342 [00:00<00:00, 1.80MB/s]
Fetching 9 files:  11% 1/9 [00:02<00:16,  2.07s/it]

Downloading (…)4d6/unet/config.json: 100% 939/939 [00:00<00:00, 4.47MB/s]



Downloading model.safetensors:   8% 105M/1.36G [00:00<00:03, 336MB/s] 
Downloading (…)ch_model.safetensors:  13% 461M/3.46G [00:01<00:06, 442MB/s]

Downloading (…)44d6/vae/config.json: 100% 611/611 [00:00<00:00, 2.70MB/s]



Downloading model.safetensors:  12% 157M/1.36G [00:00<00:03, 383MB/s]
Downloading (…)ch_model.safetensors:  15% 514M/3.46G [00:01<00:06, 455MB/s]


Downloading model.safetensors:  15% 210M/1.36G [00:00<00:02, 415MB/s]
Downloading (…)ch_model.safetensors:  16% 566M/3.46G [00:01<00:06, 460MB/s]


Downloading model.safetensors:  19% 262M/1.36G [00:00<00:02, 430MB/s]
Downloading (…)ch_model.safetensors:  18% 619M/3.46G [00:01<00:06, 457MB/s]


Downloading model.safetensors:  23% 315M/1.36G [00:00<00:02, 435MB/s]
Downloading (…)ch_model.safetensors:  19% 671M/3.46G [00:01<00:06, 455MB/s]


Downloading model.safetensors:  27% 367M/1.36G [00:00<00:02, 443MB/s]
Downloading (…)ch_model.safetensors:  21% 724M/3.46G [00:01<00:06, 445MB/s]


Downloading model.safetensors:  31% 419M/1.36G [00:01<00:02, 404MB/s]
Downloading (…)ch_model.safetensors:  22% 776M/3.46G [00:01<00:06, 413MB/s]


Downloading model.safetensors:  34% 461M/1.36G [00:01<00:02, 389MB/s]
Downloading (…)ch_model.safetensors:  24% 818M/3.46G [00:01<00:06, 392MB/s]


Downloading model.safetensors:  37% 503M/1.36G [00:01<00:02, 388MB/s]
Downloading (…)ch_model.safetensors:  25% 860M/3.46G [00:01<00:06, 388MB/s]


Downloading model.safetensors:  40% 545M/1.36G [00:01<00:02, 382MB/s]
Downloading (…)ch_model.safetensors:  26% 902M/3.46G [00:02<00:06, 385MB/s]


Downloading model.safetensors:  43% 587M/1.36G [00:01<00:02, 382MB/s]
Downloading (…)ch_model.safetensors:  27% 944M/3.46G [00:02<00:06, 392MB/s]


Downloading model.safetensors:  46% 629M/1.36G [00:01<00:01, 390MB/s]
Downloading (…)ch_model.safetensors:  28% 986M/3.46G [00:02<00:06, 385MB/s]


Downloading model.safetensors:  49% 671M/1.36G [00:01<00:01, 387MB/s]
Downloading (…)ch_model.safetensors:  30% 1.04G/3.46G [00:02<00:06, 403MB/s]


Downloading model.safetensors:  53% 724M/1.36G [00:01<00:01, 398MB/s]
Downloading (…)ch_model.safetensors:  31% 1.08G/3.46G [00:02<00:05, 407MB/s]


Downloading model.safetensors:  57% 776M/1.36G [00:01<00:01, 407MB/s]
Downloading (…)ch_model.safetensors:  33% 1.13G/3.46G [00:02<00:05, 412MB/s]


Downloading model.safetensors:  60% 818M/1.36G [00:02<00:01, 397MB/s]
Downloading (…)ch_model.safetensors:  34% 1.17G/3.46G [00:02<00:05, 413MB/s]
Downloading (…)ch_model.safetensors:  35% 1.22G/3.46G [00:02<00:06, 357MB/s]


Downloading model.safetensors:  63% 860M/1.36G [00:02<00:01, 310MB/s]
Downloading (…)ch_model.safetensors:  36% 1.26G/3.46G [00:03<00:08, 266MB/s]


Downloading model.safetensors:  66% 902M/1.36G [00:02<00:01, 254MB/s]
Downloading (…)ch_model.safetensors:  37% 1.29G/3.46G [00:03<00:09, 239MB/s]


Downloading model.safetensors:  69% 933M/1.36G [00:02<00:01, 230MB/s]
Downloading (…)ch_model.safetensors:  38% 1.32G/3.46G [00:03<00:10, 198MB/s]


Downloading model.safetensors:  71% 965M/1.36G [00:02<00:02, 196MB/s]
Downloading (…)ch_model.safetensors:  39% 1.35G/3.46G [00:03<00:10, 198MB/s]


Downloading model.safetensors:  73% 996M/1.36G [00:03<00:01, 199MB/s]
Downloading (…)ch_model.safetensors:  40% 1.38G/3.46G [00:03<00:11, 176MB/s]


Downloading model.safetensors:  75% 1.03G/1.36G [00:03<00:01, 176MB/s]
Downloading (…)ch_model.safetensors:  41% 1.41G/3.46G [00:04<00:11, 174MB/s]


Downloading model.safetensors:  77% 1.05G/1.36G [00:03<00:01, 173MB/s]


Downloading model.safetensors:  79% 1.08G/1.36G [00:03<00:01, 186MB/s]
Downloading (…)ch_model.safetensors:  41% 1.44G/3.46G [00:04<00:11, 182MB/s]


Downloading model.safetensors:  81% 1.10G/1.36G [00:03<00:01, 173MB/s]
Downloading (…)ch_model.safetensors:  42% 1.46G/3.46G [00:04<00:11, 171MB/s]


Downloading model.safetensors:  82% 1.12G/1.36G [00:03<00:01, 160MB/s]
Downloading (…)ch_model.safetensors:  43% 1.48G/3.46G [00:04<00:12, 159MB/s]


Downloading model.safetensors:  85% 1.15G/1.36G [00:04<00:01, 134MB/s]
Downloading (…)ch_model.safetensors:  44% 1.51G/3.46G [00:04<00:14, 134MB/s]
Downloading (…)ch_model.safetensors:  45% 1.54G/3.46G [00:04<00:11, 162MB/s]


Downloading model.safetensors:  87% 1.18G/1.36G [00:04<00:01, 158MB/s]


Downloading model.safetensors:  90% 1.23G/1.36G [00:04<00:00, 203MB/s]
Downloading (…)ch_model.safetensors:  45% 1.57G/3.46G [00:05<00:10, 173MB/s]
Downloading (…)ch_model.safetensors:  46% 1.60G/3.46G [00:05<00:09, 195MB/s]


Downloading model.safetensors:  92% 1.26G/1.36G [00:04<00:00, 190MB/s]
Downloading (…)ch_model.safetensors:  47% 1.64G/3.46G [00:05<00:10, 178MB/s]


Downloading model.safetensors:  95% 1.29G/1.36G [00:04<00:00, 171MB/s]
Downloading (…)ch_model.safetensors:  48% 1.66G/3.46G [00:05<00:10, 170MB/s]


Downloading model.safetensors:  96% 1.31G/1.36G [00:05<00:00, 164MB/s]
Downloading (…)ch_model.safetensors:  48% 1.68G/3.46G [00:05<00:11, 155MB/s]


Downloading model.safetensors:  98% 1.33G/1.36G [00:05<00:00, 158MB/s]
Downloading (…)ch_model.safetensors:  49% 1.70G/3.46G [00:05<00:11, 151MB/s]


Downloading model.safetensors:  99% 1.35G/1.36G [00:05<00:00, 152MB/s]
Downloading model.safetensors: 100% 1.36G/1.36G [00:05<00:00, 248MB/s]
Fetching 9 files:  56% 5/9 [00:07<00:05,  1.42s/it]
Downloading (…)ch_model.safetensors:  50% 1.74G/3.46G [00:06<00:11, 146MB/s]
Downloading (…)ch_model.safetensors:  51% 1.76G/3.46G [00:06<00:11, 151MB/s]
Downloading (…)ch_model.safetensors:  51% 1.78G/3.46G [00:06<00:10, 157MB/s]
Downloading (…)ch_model.safetensors:  52% 1.80G/3.46G [00:06<00:10, 157MB/s]
Downloading (…)ch_model.safetensors:  53% 1.82G/3.46G [00:06<00:10, 162MB/s]
Downloading (…)ch_model.safetensors:  53% 1.85G/3.46G [00:06<00:09, 166MB/s]
Downloading (…)ch_model.safetensors:  54% 1.87G/3.46G [00:06<00:09, 169MB/s]
Downloading (…)ch_model.safetensors:  54% 1.89G/3.46G [00:07<00:09, 168MB/s]
Downloading (…)ch_model.safetensors:  55% 1.91G/3.46G [00:07<00:09, 167MB/s]
Downloading (…)ch_model.safetensors:  56% 1.93G/3.46G [00:07<00:09, 161MB/s]
Downloading (…)ch_model.safetensors:  56% 1.95G/3.46G [00:07<00:09, 162MB/s]
Downloading (…)ch_model.safetensors:  57% 1.97G/3.46G [00:07<00:09, 163MB/s]
Downloading (…)ch_model.safetensors:  58% 1.99G/3.46G [00:07<00:08, 167MB/s]
Downloading (…)ch_model.safetensors:  58% 2.01G/3.46G [00:07<00:08, 173MB/s]
Downloading (…)ch_model.safetensors:  59% 2.03G/3.46G [00:07<00:08, 177MB/s]
Downloading (…)ch_model.safetensors:  60% 2.07G/3.46G [00:08<00:07, 189MB/s]
Downloading (…)ch_model.safetensors:  61% 2.10G/3.46G [00:08<00:06, 203MB/s]
Downloading (…)ch_model.safetensors:  61% 2.13G/3.46G [00:08<00:06, 211MB/s]
Downloading (…)ch_model.safetensors:  62% 2.16G/3.46G [00:08<00:05, 230MB/s]
Downloading (…)ch_model.safetensors:  64% 2.20G/3.46G [00:08<00:04, 268MB/s]
Downloading (…)ch_model.safetensors:  65% 2.24G/3.46G [00:08<00:04, 289MB/s]
Downloading (…)ch_model.safetensors:  66% 2.29G/3.46G [00:08<00:03, 305MB/s]
Downloading (…)ch_model.safetensors:  67% 2.33G/3.46G [00:08<00:03, 314MB/s]
Downloading (…)ch_model.safetensors:  68% 2.37G/3.46G [00:09<00:03, 323MB/s]
Downloading (…)ch_model.safetensors:  70% 2.41G/3.46G [00:09<00:03, 324MB/s]
Downloading (…)ch_model.safetensors:  71% 2.45G/3.46G [00:09<00:03, 332MB/s]
Downloading (…)ch_model.safetensors:  72% 2.50G/3.46G [00:09<00:03, 310MB/s]
Downloading (…)ch_model.safetensors:  73% 2.53G/3.46G [00:09<00:03, 301MB/s]
Downloading (…)ch_model.safetensors:  74% 2.56G/3.46G [00:09<00:03, 290MB/s]
Downloading (…)ch_model.safetensors:  75% 2.59G/3.46G [00:09<00:03, 273MB/s]
Downloading (…)ch_model.safetensors:  76% 2.63G/3.46G [00:09<00:02, 307MB/s]
Downloading (…)ch_model.safetensors:  78% 2.69G/3.46G [00:10<00:01, 387MB/s]
Downloading (…)ch_model.safetensors:  79% 2.75G/3.46G [00:10<00:01, 402MB/s]
Downloading (…)ch_model.safetensors:  81% 2.79G/3.46G [00:10<00:01, 375MB/s]
Downloading (…)ch_model.safetensors:  82% 2.83G/3.46G [00:10<00:01, 367MB/s]
Downloading (…)ch_model.safetensors:  83% 2.87G/3.46G [00:10<00:01, 315MB/s]
Downloading (…)ch_model.safetensors:  84% 2.92G/3.46G [00:10<00:02, 223MB/s]
Downloading (…)ch_model.safetensors:  86% 2.98G/3.46G [00:11<00:01, 287MB/s]
Downloading (…)ch_model.safetensors:  88% 3.04G/3.46G [00:11<00:01, 346MB/s]
Downloading (…)ch_model.safetensors:  89% 3.09G/3.46G [00:11<00:00, 378MB/s]
Downloading (…)ch_model.safetensors:  91% 3.15G/3.46G [00:11<00:00, 392MB/s]
Downloading (…)ch_model.safetensors:  93% 3.21G/3.46G [00:11<00:00, 432MB/s]
Downloading (…)ch_model.safetensors:  94% 3.27G/3.46G [00:11<00:00, 465MB/s]
Downloading (…)ch_model.safetensors:  96% 3.33G/3.46G [00:11<00:00, 488MB/s]
Downloading (…)ch_model.safetensors:  98% 3.40G/3.46G [00:11<00:00, 501MB/s]
Downloading (…)ch_model.safetensors: 100% 3.46G/3.46G [00:11<00:00, 289MB/s]
Fetching 9 files: 100% 9/9 [00:13<00:00,  1.46s/it]
UNet2DConditionModel: 96, [5, 10, 20, 20], 1024, True, True
U-Net converted to original U-Net
Enable xformers for U-Net
import network module: networks.lora
[Dataset 0]
caching latents.
checking cache validity...
100% 61/61 [00:00<00:00, 609172.72it/s]
caching latents...
100% 61/61 [00:04<00:00, 14.38it/s]
create LoRA network. base dim (rank): 8, alpha: 1.0
neuron dropout: p=None, rank dropout: p=None, module dropout: p=None
create LoRA for Text Encoder:
create LoRA for Text Encoder: 138 modules.
create LoRA for U-Net: 192 modules.
enable LoRA for text encoder
enable LoRA for U-Net
prepare optimizer, data loader etc.
False

===================================BUG REPORT===================================
/usr/local/lib/python3.10/dist-packages/bitsandbytes-0.41.0-py3.10.egg/bitsandbytes/cuda_setup/main.py:166: UserWarning: Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes


  warn(msg)
================================================================================
The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/lib/python3.10/dist-packages/cv2/../../lib64')}
/usr/local/lib/python3.10/dist-packages/bitsandbytes-0.41.0-py3.10.egg/bitsandbytes/cuda_setup/main.py:166: UserWarning: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}
The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-a100-s-f30k1mvrf8l2 --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}
The following directories listed in your path were found to be non-existent: {PosixPath('/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages')}
The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}
The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}
The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('8013'), PosixPath('http')}
CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...
/usr/local/lib/python3.10/dist-packages/bitsandbytes-0.41.0-py3.10.egg/bitsandbytes/cuda_setup/main.py:166: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We select the PyTorch default libcudart.so, which is {torch.version.cuda},but this might missmatch with the CUDA version that is needed for bitsandbytes.To override this behavior set the BNB_CUDA_VERSION=<version string, e.g. 122> environmental variableFor example, if you want to use the CUDA version 122BNB_CUDA_VERSION=122 python ...OR set the environmental variable in your .bashrc: export BNB_CUDA_VERSION=122In the case of a manual override, make sure you set the LD_LIBRARY_PATH, e.g.export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.2
  warn(msg)
DEBUG: Possible options found for libcudart.so: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}
CUDA SETUP: PyTorch settings found: CUDA_VERSION=117, Highest Compute Capability: 8.0.
CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md
CUDA SETUP: Required library version not found: libbitsandbytes_cuda117.so. Maybe you need to compile it from source?
CUDA SETUP: Defaulting to libbitsandbytes_cpu.so...

================================================ERROR=====================================
CUDA SETUP: CUDA detection failed! Possible reasons:
1. You need to manually override the PyTorch CUDA version. Please see: "https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md
2. CUDA driver not installed
3. CUDA not installed
4. You have multiple conflicting CUDA libraries
5. Required library not pre-compiled for this bitsandbytes release!
CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.
CUDA SETUP: The CUDA version for the compile might depend on your conda install. Inspect CUDA version via `conda list | grep cuda`.
================================================================================

CUDA SETUP: Something unexpected happened. Please compile from source:
git clone https://github.com/TimDettmers/bitsandbytes.git
cd bitsandbytes
CUDA_VERSION=117 make cuda11x
python setup.py install
CUDA SETUP: Setup Failed!
Traceback (most recent call last):
  File "/content/kohya_ss/./train_network.py", line 990, in <module>
    trainer.train(args)
  File "/content/kohya_ss/./train_network.py", line 325, in train
    optimizer_name, optimizer_args, optimizer = train_util.get_optimizer(args, trainable_params)
  File "/content/kohya_ss/library/train_util.py", line 3410, in get_optimizer
    import bitsandbytes as bnb
  File "/usr/local/lib/python3.10/dist-packages/bitsandbytes-0.41.0-py3.10.egg/bitsandbytes/__init__.py", line 6, in <module>
    from . import cuda_setup, utils, research
  File "/usr/local/lib/python3.10/dist-packages/bitsandbytes-0.41.0-py3.10.egg/bitsandbytes/research/__init__.py", line 1, in <module>
    from . import nn
  File "/usr/local/lib/python3.10/dist-packages/bitsandbytes-0.41.0-py3.10.egg/bitsandbytes/research/nn/__init__.py", line 1, in <module>
    from .modules import LinearFP8Mixed, LinearFP8Global
  File "/usr/local/lib/python3.10/dist-packages/bitsandbytes-0.41.0-py3.10.egg/bitsandbytes/research/nn/modules.py", line 8, in <module>
    from bitsandbytes.optim import GlobalOptimManager
  File "/usr/local/lib/python3.10/dist-packages/bitsandbytes-0.41.0-py3.10.egg/bitsandbytes/optim/__init__.py", line 6, in <module>
    from bitsandbytes.cextension import COMPILED_WITH_CUDA
  File "/usr/local/lib/python3.10/dist-packages/bitsandbytes-0.41.0-py3.10.egg/bitsandbytes/cextension.py", line 20, in <module>
    raise RuntimeError('''
RuntimeError: 
        CUDA Setup failed despite GPU being available. Please run the following command to get more information:

        python -m bitsandbytes

        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues
Traceback (most recent call last):
  File "/usr/local/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py", line 47, in main
    args.func(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 994, in launch_command
    simple_launcher(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 636, in simple_launcher
    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)
subprocess.CalledProcessError: Command '['/usr/bin/python3', './train_network.py', '--v2', '--v_parameterization', '--enable_bucket', '--min_bucket_reso=256', '--max_bucket_reso=2048', '--pretrained_model_name_or_path=stabilityai/stable-diffusion-2-1', '--train_data_dir=/content/drive/MyDrive/AI_PICS/training/elisabeth_borne_512px', '--resolution=512,512', '--output_dir=/content/drive/MyDrive/AI_PICS/Lora', '--network_alpha=1', '--save_model_as=safetensors', '--network_module=networks.lora', '--text_encoder_lr=5e-05', '--unet_lr=0.0001', '--network_dim=8', '--output_name=lastLundi', '--lr_scheduler_num_cycles=1', '--no_half_vae', '--learning_rate=0.0001', '--lr_scheduler=cosine', '--lr_warmup_steps=610', '--train_batch_size=1', '--max_train_steps=6100', '--save_every_n_epochs=1', '--mixed_precision=bf16', '--save_precision=bf16', '--cache_latents', '--optimizer_type=AdamW8bit', '--max_data_loader_n_workers=0', '--bucket_reso_steps=64', '--xformers', '--bucket_no_upscale', '--noise_offset=0.0']' returned non-zero exit status 1